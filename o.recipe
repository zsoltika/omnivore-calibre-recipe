# -*- coding: utf-8 -*-
__license__   = 'GPL v3'
__copyright__ = '2024, Zsolt Botykai <zsolt.botykai@gmail.com>'
'''
A recipe for Calibre to fetch my Omnivore reading list, and create an EPUB
file'''

import datetime
import os
import string
import sys

from omnivoreql import OmnivoreQL

from    calibre.web.feeds.news       import BasicNewsRecipe
from    calibre.ebooks.BeautifulSoup import Tag, NavigableString

NOW   = datetime.datetime.now()
TODAY = NOW.strftime("%Y-%m-%d")
APIKEY = os.environ['OMNICALAPIKEY']

class MyOmnivore(BasicNewsRecipe):
    title                   = u'My Omnivore reading list'
    __author__              = u'Zsolt Botykai '
    description             = u'My Omnivore reading list'
    INDEX                   = 'http://omnivore.app/'
    language                = 'en'
    simultaneous_downloads  = 2
    timefmt                 = ' [%Y-%m-%d %H:%M]'
    tags                    = u'reading-list, articles, newspapers'
    publication_type        = 'magazine'
    remove_javascript       = True
    remove_empty_feeds      = True
    no_stylesheets          = True
    encoding = 'UTF-8'

    # without the background color setup, the conversion to pdf produced
    # black pages with white text
    extra_css = '''
                    body { background-color: white; color: black; }
                    p { text-align: justify; margin_top: 0px; margin-bottom: 0px; }
                '''

    def parse_index(self):
        actdir = os.getcwd()
        token = open(APIKEY, 'r').read().strip()
        oc = OmnivoreQL(token)
        profile = oc.get_profile()
        user=profile['me']['profile']['username']
        feeds=[]
        def getarticles(what):
            oarticles = []
            for a in articles['search']['edges']:
                article = oc.get_article(username=user, slug=a['node']['slug'])
                if article['article']['article']['isArchived'] is False:
                    content    = ''
                    title      = article['article']['article']['title']
                    title      = title.replace('&','&amp;')
                    article_id = article['article']['article']['id']
                    url        = article['article']['article']['url']
                    author     = article['article']['article']['author']
                    labels     = article['article']['article']['labels']
                    if not author: author = "No author"
                    if not title: author = "No title"
                    if not url: author = "No URL"
                    if labels and 'name' in labels[0]:
                        labellist = [dict['name'] for dict in labels]
                    clabel = ', '.join(['#' + str(e) + ' ' for e in labellist])
                    if author:
                        content += '<h4>' + author + '</h4>'
                    if title:
                        content += '<h3>' + title + '</h3>'
                    content += article['article']['article']['content']
                    if url:
                        content += '<br /><h6>Eredeti link: ' + url + '</h6>'
                    if clabel:
                        content += '<h6>Címkék: ' + clabel + '</h6>'
                    artfile = actdir + '/' + article_id + '.html'
                    with open(artfile, 'w') as f:
                        f.write(content)
                    oarticles.append(
                        {
                            'title'       : title,
                            'url'         : 'file://'+artfile,
                            'date'        : TODAY,
                            'description' : ''})
                    if article_id:
                        oc.archive_article(article_id)
                        self.log("Archived: " + title + "; id: " + article_id)

            section_title = what + ' mentett cikkek @ ' + TODAY
            feeds.append((section_title, oarticles))

        # There will be two sections in the generated EPUB:
        # One with (unread) articles saved ages ago and one with newly saved
        # articles.
        articles = oc.get_articles(limit=20, query='sort:saved-asc')
        getarticles("Régen")
        articles = oc.get_articles(limit=20, query='sort:saved-desc')
        getarticles("Mostanában")

        return feeds
